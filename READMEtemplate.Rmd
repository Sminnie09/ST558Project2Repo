---
title: "ST558 Project 2" 
author: "Noel Hilliard"
date: "July 3, 2020"
output:
  rmarkdown::github_document:
    toc: TRUE
params:
  day: "monday"
---

Project Objective: The goal is to create models for predicting the `shares` variable from the dataset. You will create two models: a linear regression model and a non-linear model (each of your choice). You will use the parameter functionality of markdown to automatically generate an analysis report for each `weekday_is_*` variable (so youâ€™ll end up with seven total outputted documents).

```{r rmarkdown params, echo = FALSE, eval = FALSE, message = FALSE}
library(rmarkdown)
library(tidyverse)
library(Hmisc)

#days of the week
days <- c("monday", "tuesday", "wednesday")

#days <- c("monday", "tuesday", "wednesday",
           #"thursday", "friday", "aturday",
           #"sunday")

#create file names
output_file <- paste0(capitalize(days), "Analysis.md")

#create a list for each day of the week with the day as parameter
params <- lapply(days, FUN = function(x){list(day = x)})

#put into data frame
#reports <- tibble(days, filename = output_file, params = purrr::map(days, ~list(day = .)))
reports <- tibble(filename = output_file, params)
```

```{r rmarkdown automation, eval = FALSE, echo = FALSE}
apply(reports, MARGIN = 1, FUN = function(x){
  render("template.Rmd", 
         output_file = x[[1]], params = x[[2]])
})
```

# Introduction Online News Popularity Data

The data used for this analysis was obtained from the [UCI Machine Learning Reposititory](https://archive.ics.uci.edu/ml/datasets/Online+News+Popularity). The data set summarizes a set of features about articles published by Mashable over a two year period. The purpose of this analysis is to predict the number of shares in social networks using select features from the data set. Two types of methods will be used to predict the `shares`. The first model discussed is a bagged tree model. For this analysis, the `shares` were divided into two groups (< 1400 and >= 1400) to create a binary classification problem. The second model discussed is a multiple linear regression model. Both types of models were trained/tuned using the training data set and then then predictions were made using the test data set.

The following libraries are loaded for the analysis.

```{r libraries, echo = TRUE, message = FALSE}
library(ggplot2)
library(Hmisc)
library(rmarkdown)
library(tidyverse)
library(corrplot)
library(knitr)
library(caret)

```

# `r params$day` Data

The full data set contained data for all days of the week. This analysis will focus on the data from `r params$day`. Once the data was filtered for `r params$day`, the `shares` variable was divided into two groups: < 1400 and >= 1400 in preparation for fitting the bagged tree model.

```{r read/filter data, echo = TRUE, message = FALSE}

#read in data
newsData <-read_csv("S:/ST558/Homeworks/Project 2/ST558 Project 2/OnlineNewsPopularity.csv")
newsData$shares_group <- NA

#filter for day of week
weekdayData <- filter(newsData, newsData[[paste0("weekday_is_",params$day)]] == "1")


#split shares into 2 groups
for (i in 1:length(weekdayData$shares)){
  
  if(weekdayData$shares[i] < 1400){
    weekdayData$shares_group[i] <- "below 1400"
  }
  
  if(weekdayData$shares[i] >= 1400){
    weekdayData$shares_group[i] <- "above 1400"
  }
}

weekdayData$shares_group <- as.factor(weekdayData$shares_group)

```

The following variables were used in this analysis to predict the `shares` variable:

* `num_keywords` : Number of keywords in the metadata.
* `avg_positive_polarity` : Average polarity of positive words.
* `num_videos`: Number of videos.
* `num_imgs`: Number of images.
* `max_postive_polarity`: Maximum polarity of positive words.
* `title_subjectivity`: Title subjectivity.
* `rate_negative_words`: Rate of negative words among non-neutral tokens.
* `n_unique_tokens`: Number of words in the title.
* `average_token_length`: Average length of the words in the content.
* `global_rate_positive_words`: Rate of positive words in the content.
* `shares`: Number of shares.

The data frame below shows the subsetted data set with only the variables of interest for this analysis.

```{r select variables, echo = TRUE}

weekdayData <- weekdayData %>% select(num_keywords, avg_positive_polarity, num_videos, num_imgs, 
           max_positive_polarity, title_subjectivity, rate_negative_words,
           n_unique_tokens, average_token_length, global_rate_positive_words, shares, shares_group)

head(weekdayData)
```

The subsetted data set was randomly sampled using the `sample` function. The training data set consists of 70% of the data and the testing data set consists of 30% of the data. The `set.seed` function was used to make the work reproducible.

```{r train/test data, echo = TRUE}

#Create test/train data sets from filtered data set
set.seed(1)
train <- sample(1:nrow(weekdayData), size = nrow(weekdayData)*0.7)
test <- dplyr::setdiff(1:nrow(weekdayData), train)
weekdayDataTrain <- weekdayData[train, ]
weekdayDataTest <- weekdayData[test, ]
```

# Summary Statistics

This section covers some basic summary statistics about the variables in the training data set. 

## Histogram

The histogram below shows the distribution of `shares` using the training data set.

```{r histogram, echo = TRUE}
g <- ggplot(weekdayDataTrain, aes(x = shares))
g + geom_histogram(bins = 100)
```

The bar graph below shows the counts for the two groups of shares.

```{r bar plot, echo = TRUE}

g <- ggplot(data = weekdayDataTrain, aes(x = shares_group))
g + geom_bar() + labs(x = "Shares Group", title = (paste0(capitalize(params$day)," Shares Groups")))
```

```{r shares_group count, echo = TRUE}
table(weekdayDataTrain$shares_group)
```

```{r TrainData stat summary, echo = TRUE}

TrainStatSum <- function(group){
  data <- weekdayDataTrain %>% filter(shares_group == group) %>% 
    select(num_keywords, avg_positive_polarity, num_videos, num_imgs, 
           max_positive_polarity, title_subjectivity, rate_negative_words,
           n_unique_tokens, average_token_length, global_rate_positive_words)
           kable(apply(data, 2, summary, col.names = c("num_keywords", 
           "avg_positive_polarity", "num_videos", "num_imgs", "max_positive_polarity", 
           "title_subjectivity", "rate_negative_words", "n_unique_tokens", "average_token_length",
           "global_rate_positive_words")))
}

```

```{r above 1400, echo = TRUE}
TrainStatSum("above 1400")
```

```{r below 1400, echo = TRUE}
TrainStatSum("below 1400")
```

```{r correlation, echo = TRUE}
correlation <- cor(weekdayDataTrain %>% select(num_keywords, avg_positive_polarity, num_videos, num_imgs, 
           max_positive_polarity, title_subjectivity, rate_negative_words,
           n_unique_tokens, average_token_length, global_rate_positive_words), method = "spearman")

corrplot(correlation, type = "upper", tl.pos = "lt")
```


# Modeling

## Ensemble Model: Bagged Tree

```{r bagged tree , echo = TRUE, message = FALSE}

set.seed(1)
trCtrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3)

bag_fit <- train(shares_group ~ num_keywords + avg_positive_polarity + num_videos + num_imgs, 
                 data = weekdayDataTrain, method = "treebag", trControl = trCtrl, 
                 preProcess = c("center", "scale"), na.action = na.pass)

bag_fit
```

```{r predict bag tree , echo = TRUE}
bag_pred <- predict(bag_fit, newdata = weekdayDataTest)

head(bag_pred)
```

```{r bag fit info , echo = TRUE}
bag_fitInfo <- tbl_df(data.frame(bag_pred, weekdayDataTest$shares_group, weekdayDataTest$num_keywords, 
                                weekdayDataTest$avg_positive_polarity,
                                 weekdayDataTest$num_videos, weekdayDataTest$num_imgs))

bag_fitInfo
```

```{r bag table , echo = TRUE}
bag_tbl <- table(bag_fitInfo$bag_pred, bag_fitInfo$weekdayDataTest.shares_group)

bag_tbl
```

```{r bag misclass, echo = TRUE}
bag_misClass <- 1 - sum(diag(bag_tbl))/sum(bag_tbl)

bag_misClass
```

## Select Best Multiple Linear Regression Model

```{r mlr, echo = TRUE}
mlrFit1 <- lm(shares ~ num_keywords + avg_positive_polarity + 
                num_videos + num_imgs, data = weekdayDataTrain)

mlrFit2 <- lm(shares ~ max_positive_polarity + title_subjectivity, 
              data = weekdayDataTrain)

mlrFit3 <- lm(shares ~ num_keywords + rate_negative_words,
              data = weekdayDataTrain)

mlrFit4 <- lm(shares ~ n_unique_tokens + average_token_length + 
                 global_rate_positive_words, data = weekdayDataTrain)

```

```{r compare fit, echo = TRUE}

library(MuMIn)

compareFitStats <- function(mlrFit1, mlrFit2, mlrFit3, mlrFit4){
  fitStats <- data.frame(fitStat = c("Adj R Square", "AIC", "BIC"),
  col1 = c(round(summary(mlrFit1)$adj.r.squared, 5), AIC(mlrFit1),
                 BIC(mlrFit1)),
  col2 = c(round(summary(mlrFit2)$adj.r.squared, 5), AIC(mlrFit2),
                 BIC(mlrFit2)),
  col3 = c(round(summary(mlrFit3)$adj.r.squared, 5), AIC(mlrFit3),
                BIC(mlrFit3)),
  col4 = c(round(summary(mlrFit4)$adj.r.squared, 5), AIC(mlrFit4),
                BIC(mlrFit4)))
  
  #put names in data frame
  calls <- as.list(match.call())
  calls[[1]] <- NULL
  names(fitStats[2:5]) <- unlist(calls)
  fitStats
}
```

```{r fit stats, echo = TRUE}
fitStats <- compareFitStats(mlrFit1, mlrFit2, mlrFit3, mlrFit4)
```

```{r compare rmse, echo = TRUE}
mlrFit1_pred <- predict(mlrFit1, newdata = weekdayDataTest)
RMSE(weekdayDataTest$shares, mlrFit1_pred)

mlrFit4_pred <- predict(mlrFit4, newdata = weekdayDataTest)
RMSE(weekdayDataTest$shares, mlrFit4_pred)
```

