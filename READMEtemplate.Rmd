---
title: "ST558 Project 2" 
author: "Noel Hilliard"
date: "July 3, 2020"
output:
  rmarkdown::github_document:
    toc: TRUE
params:
  day: "monday"
---

Project Objective: The goal is to create models for predicting the `shares` variable from the dataset. You will create two models: a linear regression model and a non-linear model (each of your choice). You will use the parameter functionality of markdown to automatically generate an analysis report for each `weekday_is_*` variable (so youâ€™ll end up with seven total outputted documents).

```{r rmarkdown params, echo = FALSE, eval = FALSE, message = FALSE}
library(rmarkdown)
library(tidyverse)
library(Hmisc)

#days of the week
days <- c("monday", "tuesday", "wednesday")

#days <- c("monday", "tuesday", "wednesday",
           #"thursday", "friday", "aturday",
           #"sunday")

#create file names
output_file <- paste0(capitalize(days), "Analysis.md")

#create a list for each day of the week with the day as parameter
params <- lapply(days, FUN = function(x){list(day = x)})

#put into data frame
#reports <- tibble(days, filename = output_file, params = purrr::map(days, ~list(day = .)))
reports <- tibble(filename = output_file, params)
```

```{r rmarkdown automation, eval = FALSE, echo = FALSE, message = FALSE}
apply(reports, MARGIN = 1, FUN = function(x){
  render("READMEtemplate.Rmd", 
         output_file = x[[1]], params = x[[2]])
})
```

# Introduction Online News Popularity Data

The data used for this analysis was obtained from the [UCI Machine Learning Reposititory](https://archive.ics.uci.edu/ml/datasets/Online+News+Popularity). The data set summarizes a set of features about articles published by Mashable over a two year period. The purpose of this analysis is to predict the number of shares in social networks using select features from the data set. Two types of methods will be used to predict the `shares`. The first model discussed is a bagged tree model. For this analysis, the `shares` were divided into two groups (< 1400 and >= 1400) to create a binary classification problem. The second model discussed is linear regression. Both types of models were trained/tuned using the training data set and then then predictions were made using the test data set.

The following libraries are loaded for the analysis.

```{r libraries, echo = TRUE, message = FALSE}
library(ggplot2)
library(Hmisc)
library(rmarkdown)
library(tidyverse)
library(corrplot)
library(knitr)
library(caret)

```

# `r capitalize(params$day)` Data

The full data set contained data for all days of the week. This analysis will focus on the data from `r params$day`. Once the data was filtered for `r params$day`, the `shares` variable was divided into two groups: < 1400 and >= 1400 in preparation for fitting the bagged tree model.

```{r read/filter data, echo = TRUE, message = FALSE}

#read in data
newsData <-read_csv("S:/ST558/Homeworks/Project 2/ST558 Project 2/OnlineNewsPopularity.csv")
newsData$shares_group <- NA

#filter for day of week
weekdayData <- filter(newsData, newsData[[paste0("weekday_is_",params$day)]] == "1")


#split shares into 2 groups
for (i in 1:length(weekdayData$shares)){
  
  if(weekdayData$shares[i] < 1400){
    weekdayData$shares_group[i] <- "below 1400"
  }
  
  if(weekdayData$shares[i] >= 1400){
    weekdayData$shares_group[i] <- "above 1400"
  }
}

weekdayData$shares_group <- as.factor(weekdayData$shares_group)

```

The following variables were used in this analysis to predict the `shares` variable:

* `num_keywords` : Number of keywords in the metadata.
* `avg_positive_polarity` : Average polarity of positive words.
* `num_videos`: Number of videos.
* `num_imgs`: Number of images.
* `max_postive_polarity`: Maximum polarity of positive words.
* `title_subjectivity`: Title subjectivity.
* `rate_negative_words`: Rate of negative words among non-neutral tokens.
* `n_unique_tokens`: Number of words in the title.
* `average_token_length`: Average length of the words in the content.
* `global_rate_positive_words`: Rate of positive words in the content.
* `shares`: Number of shares.

The data frame below shows the subsetted data set with only the variables of interest for this analysis.

```{r select variables, echo = TRUE}

weekdayData <- weekdayData %>% select(num_keywords, avg_positive_polarity, num_videos, num_imgs, 
           max_positive_polarity, title_subjectivity, rate_negative_words,
           n_unique_tokens, average_token_length, global_rate_positive_words, shares, shares_group)

head(weekdayData)
```

The subsetted data set was randomly sampled using the `sample` function. The training data set consists of 70% of the data and the testing data set consists of 30% of the data. The `set.seed` function was used to make the work reproducible.

```{r train/test data, echo = TRUE}

#Create test/train data sets from filtered data set
set.seed(1)
train <- sample(1:nrow(weekdayData), size = nrow(weekdayData)*0.7)
test <- dplyr::setdiff(1:nrow(weekdayData), train)
weekdayDataTrain <- weekdayData[train, ]
weekdayDataTest <- weekdayData[test, ]
```

# Summary Statistics

This section covers some basic summary statistics about the variables in the training data set. 

## Histogram

The histogram below shows the distribution of `shares` using the training data set. The majority of the number of shares are on the lower end with some higher outliers. The `geom_histogram` function from the `ggplot2` library was used to create the histogram.

```{r histogram, echo = TRUE}
g <- ggplot(weekdayDataTrain, aes(x = shares))
g + geom_histogram(bins = 100)
```

## Bar Plot

The bar graph below shows the counts for the two groups of `shares` using the training data set. The `geom_bar` function from the `ggplot2` library was used to create the bar plot.

```{r bar plot, echo = TRUE}

g <- ggplot(data = weekdayDataTrain, aes(x = shares_group))
g + geom_bar() + labs(x = "Shares Group", title = (paste0(capitalize(params$day)," Shares Groups")))
```

## Numerical Summary

This is a numerical summary of the counts of shares in the two groups using the training data set. The `table` function was used to create the frequency table.

```{r shares_group count, echo = TRUE}
table(weekdayDataTrain$shares_group)

```

This is a summary of the `shares` variable in the training data set which inlcudes: minimum, 1st quartile, median, mean, 3rd quartile, and maximum.

```{r shares summary, echo = TRUE}
summary(weekdayDataTrain$shares)
```

The `TrainStatSum` function calculates a statistical summary for all the variables of interest in the two `shares` groups.

```{r TrainStatSum function, echo = TRUE}
TrainStatSum <- function(group){
  data <- weekdayDataTrain %>% filter(shares_group == group) %>% 
    select(num_keywords, avg_positive_polarity, num_videos, num_imgs, 
           max_positive_polarity, title_subjectivity, rate_negative_words,
           n_unique_tokens, average_token_length, global_rate_positive_words)
           kable(apply(data, 2, summary, col.names = c("num_keywords", 
           "avg_positive_polarity", "num_videos", "num_imgs", "max_positive_polarity", 
           "title_subjectivity", "rate_negative_words", "n_unique_tokens", "average_token_length",
           "global_rate_positive_words")))
}
```

The function is called for the `shares` above 1400.

```{r above 1400 stat summary, echo = TRUE}
TrainStatSum("above 1400")
```

The function is called for the `shares` below 1400.

```{r below 1400 stat summary, echo = TRUE}
TrainStatSum("below 1400")
```


# Modeling

This section will fit two types of models to predict the `shares` variable.The first section discusses a an ensemble model and the second section discusses the selection of a linear regression model from a collection of linear regression models. The training data set was used to fit the two models and the test data set was used to make predictions.

## Ensemble Model: Bagged Tree

The `caret` package was used to fit the bagged tree model. Repeated cross validation was used in the `trainControl` function. This result was fed into the `train` function with the method specified as `treebag` for a bagged tree model to train the tree on the sample. The predictors were centered and scaled in the `preProcess` argument. This method does not have any tuning parameters. The best model fit is shown below.

```{r bagged tree , echo = TRUE, message = FALSE}

set.seed(1)
trCtrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3)

bag_fit <- train(shares_group ~ num_keywords + avg_positive_polarity + num_videos + num_imgs, 
                 data = weekdayDataTrain, method = "treebag", trControl = trCtrl, 
                 preProcess = c("center", "scale"), na.action = na.pass)

bag_fit
```

The best bagged tree model fit was used to predict the `shares` groups using the test data set. The top of the bagged tree model prediction is shown below.

```{r predict bag tree , echo = TRUE}
bag_pred <- predict(bag_fit, newdata = weekdayDataTest)

head(bag_pred)
```

A data frame of the prediction based on the test data set and the test data set are shown below.

```{r bag fit info , echo = TRUE}
bag_fitInfo <- tbl_df(data.frame(bag_pred, weekdayDataTest$shares_group, weekdayDataTest$num_keywords, 
                                weekdayDataTest$avg_positive_polarity,
                                 weekdayDataTest$num_videos, weekdayDataTest$num_imgs))

bag_fitInfo
```

A frequency table of the bagged tree prediction and the `shares_group` column from the test data set are shown below. This table will be used to calculate the misclassification rate. The `table` function was used to create the frequency table.

```{r bag table , echo = TRUE}
bag_tbl <- table(bag_fitInfo$bag_pred, bag_fitInfo$weekdayDataTest.shares_group)

bag_tbl
```

The misclassification rate for the bagged tree model is shown below. 

```{r bag misclass, echo = TRUE}
bag_misClass <- 1 - sum(diag(bag_tbl))/sum(bag_tbl)

bag_misClass
```

## Select Linear Regression Model

This section will discuss methods for selecting a linear regression model from a collection of linear regression models. Correlations of numeric predictor variables with each other and with the response variable `shares` were used to create the collection of variables. Predictor variables with lower correlations with each other and the `shares` variable were used because higher correlations may interfere with model performance.

The figure below shows a correlation plot of the correlations between a subset of predictor variables from the full data set that were in the training data set. The `cor` function was used from the `corrplot` library. 

```{r correlation, echo = TRUE}
correlation <- cor(weekdayDataTrain %>% select(num_keywords, avg_positive_polarity, num_videos, num_imgs, 
           max_positive_polarity, title_subjectivity, rate_negative_words,
           n_unique_tokens, average_token_length, global_rate_positive_words, shares), method = "spearman")

corrplot(correlation, type = "upper", tl.pos = "lt")
corrplot(correlation, type = "lower", method = "number", add = TRUE, tl.pos = "n")

```

Linear regression models can be formed based on the predictor variables with lower correlations. In this example, two simple linear regression models and three multiple linear regression models were selected based on variables with lower correlations. The `lm` function was used to fit the models with the training data set.

```{r mlr, echo = TRUE}
mlrFit1 <- lm(shares ~ num_keywords + num_imgs, data = weekdayDataTrain)

mlrFit2 <- lm(shares ~ num_keywords, 
              data = weekdayDataTrain)

mlrFit3 <- lm(shares ~ num_imgs + num_videos + global_rate_positive_words,
              data = weekdayDataTrain)

mlrFit4 <- lm(shares ~ n_unique_tokens + max_positive_polarity, data = weekdayDataTrain)

mlrFit5 <- lm(shares ~ global_rate_positive_words, weekdayDataTrain)
```

To select the best linear regression model, adjusted R square, AIC, and BIC values for each model fit are used to determine which model predicts the `shares` value the best.

```{r compare fit, echo = TRUE}

library(MuMIn)

compareFitStats <- function(mlrFit1, mlrFit2, mlrFit3, mlrFit4, mlrFit5){
  fitStats <- data.frame(fitStat = c("Adj R Square", "AIC", "BIC"),
  Fit1 = c(round(summary(mlrFit1)$adj.r.squared, 5), AIC(mlrFit1),
                 BIC(mlrFit1)),
  Fit2 = c(round(summary(mlrFit2)$adj.r.squared, 5), AIC(mlrFit2),
                 BIC(mlrFit2)),
  Fit3 = c(round(summary(mlrFit3)$adj.r.squared, 5), AIC(mlrFit3),
                BIC(mlrFit3)),
  Fit4 = c(round(summary(mlrFit4)$adj.r.squared, 5), AIC(mlrFit4),
                BIC(mlrFit4)),
  Fit5 = c(round(summary(mlrFit5)$adj.r.squared, 5), AIC(mlrFit5),
                BIC(mlrFit5)))
  
  #put names in data frame
  calls <- as.list(match.call())
  calls[[1]] <- NULL
  names(fitStats[2:6]) <- unlist(calls)
  fitStats
}
```

The table below shows the adjusted R square, AIC, and BIC for each model fit. Larger adjusted R square values and smaller AIC and BIC values are better.

```{r fit stats, echo = TRUE}
fitStats <- compareFitStats(mlrFit1, mlrFit2, mlrFit3, mlrFit4, mlrFit5)

fitStats
```

For this example the first linear regression model was selected to demonstrate predicting with test data and calculating the root mean square error (RMSE). RMSE for the testing data set are also used to select the best model. The `predict` function was used to make a prediction and the `RMSE` function was used to calculate the RMSE.

```{r compare rmse Test, echo = TRUE}
mlrFit1_predTest <- predict(mlrFit1, newdata = weekdayDataTest)

head(mlrFit1_predTest)

RMSE(weekdayDataTest$shares, mlrFit1_predTest)
```

